{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Melting Points of Molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdt import datasets\n",
    "from smdt import data_processing\n",
    "from smdt import molecular_descriptors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows: 20\n",
      "n_columns: 2\n",
      "column names: ['SMILES', 'Target']\n",
      "                                              SMILES  Target\n",
      "0                                     O=C1Cc2ccccc21    14.0\n",
      "1  Clc1ccc(cc1)C1c2c(OC(N)=C1C#N)[nH][nH0]c2C(F)(F)F    20.5\n",
      "2                      O=C(OC)C(=Cc1ccccc1)Cc1ccccc1    27.5\n",
      "3                         FC(F)(F)c1[nH0]cc2ccccc2c1    30.5\n",
      "4                                O=C(OC1Cc2ccccc21)C    31.0\n"
     ]
    }
   ],
   "source": [
    "data = datasets.melting_point()[:20]\n",
    "print('n_rows: %d'%(data.shape[0]))\n",
    "print('n_columns: %d'%(data.shape[1]))\n",
    "print('column names: %s' %list(data.columns))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Molecular Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Molecular Descriptors...\n",
      "Row 20 out of 20\n",
      "Calculating Molecular Descriptors Completed.\n"
     ]
    }
   ],
   "source": [
    "data = molecular_descriptors.getAllDescriptors(data)\n",
    "data.to_csv('Data_with_Molecular_Descriptors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows: 20\n",
      "n_columns: 760\n",
      "        W        AW         J         Xu      GMTI   Pol         DZ       Ipc  \\\n",
      "0    82.0  2.277778  2.634238   8.652965  2.568202   9.0  19.000000  2.157035   \n",
      "1  1046.0  4.134387  2.257916  21.532542  3.640283  40.0  53.833333  5.213381   \n",
      "2   742.0  4.339181  2.267054  19.046127  3.490801  24.0  40.000000  4.438837   \n",
      "3   288.0  3.164835  2.627008  13.842646  3.076640  20.0  33.000000  3.208180   \n",
      "4   203.0  3.075758  2.146253  12.143010  2.928908  13.0  26.000000  2.748027   \n",
      "\n",
      "    BertzCT      Thara   ...    ATSe8  ATSp1  ATSp2  ATSp3  ATSp4  ATSp5  \\\n",
      "0  2.419997  20.200000   ...    0.000  2.347  2.477  2.187  1.363  0.375   \n",
      "1  2.920743  86.101190   ...    2.652  3.044  3.387  3.444  3.413  3.332   \n",
      "2  2.745333  58.915873   ...    2.398  2.963  3.183  3.103  2.987  3.027   \n",
      "3  2.664754  39.761905   ...    0.000  2.581  2.841  2.760  2.318  1.877   \n",
      "4  2.501565  30.352381   ...    0.000  2.515  2.641  2.515  2.177  1.851   \n",
      "\n",
      "   ATSp6  ATSp7  ATSp8  Target  \n",
      "0  0.000  0.000  0.000    14.0  \n",
      "1  3.056  2.566  1.925    20.5  \n",
      "2  3.027  2.822  2.398    27.5  \n",
      "3  1.363  0.670  0.000    30.5  \n",
      "4  1.591  0.898  0.000    31.0  \n",
      "\n",
      "[5 rows x 760 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data_with_Molecular_Descriptors.csv')\n",
    "print('n_rows: %d'%(data.shape[0]))\n",
    "print('n_columns: %d'%(data.shape[1]))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from smdt import utils\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "def svr_model(data, standardize = True, feature_selection = 'univariate', n_features = 10, cv_metric = 'r2'):\n",
    "    \"\"\"\n",
    "    Train a Support Vector Regression model\n",
    "    Papameters:\n",
    "        data: pandas.DataFrame\n",
    "            Descriptor and Target data\n",
    "        standardize: boolean, default True\n",
    "            Scales features to zero mean and unit variance\n",
    "        feature_selection: str, default 'univariate feature selection'\n",
    "            Specify strategy for feature selection. Choose between 'remove_low_variance_features','univariate feature selection',\n",
    "            'tree_based_feature_selection'\n",
    "        n_features: int, default 10\n",
    "            Used only in univariate feature selection\n",
    "        cv_metric: str, default 'r2'\n",
    "    \"\"\"\n",
    "    print('Found dataset of shape:  %s' %str(data.shape))\n",
    "    print('\\nData Split started...')\n",
    "    train, test = utils.test_train_split(data)\n",
    "    print('Train data shape: %s' %str(train.shape))\n",
    "    print('Test data shape: %s' %str(test.shape))\n",
    "    print('Data Split completed.')\n",
    "\n",
    "    if standardize == True:\n",
    "        print('\\nData Scaling started...')    \n",
    "        train, test = data_processing.data_standardization(train, test)\n",
    "        print('Data Scaling completed.')    \n",
    "\n",
    "    print('\\nSelecting Features...')\n",
    "    if feature_selection == 'low variance':\n",
    "        train = data_processing.remove_low_variance_features(train)\n",
    "        test = test[train.columns]\n",
    "    elif feature_selection == 'univariate':\n",
    "        train = data_processing.univariate_feature_selection(train,n_features)\n",
    "        test = test[train.columns]\n",
    "    elif feature_selection == 'tree based':\n",
    "        train = data_processing.tree_based_feature_selection(train)\n",
    "        test = test[train.columns]\n",
    "    print('New train data shape: %s' %str(train.shape))\n",
    "    print('New test data shape: %s' %str(test.shape))\n",
    "    print('Feature selection completed.')\n",
    "\n",
    "    train_descriptors, train_target = utils.descriptor_target_split(train)\n",
    "    test_descriptors, test_target = utils.descriptor_target_split(test)\n",
    "    \n",
    "    parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'epsilon' : [0.1, 1], 'C': [1e0, 1e1, 1e2, 1e3],\n",
    "                               'gamma': np.logspace(-2, 2, 5)}\n",
    "    model = SVR()\n",
    "    print('\\nGridSearchCV Parameter Grid:')\n",
    "    print(parameters)\n",
    "    print('\\nStarted GridSearchCV on Training data...')\n",
    "    clf = GridSearchCV(model, parameters,scoring=cv_metric,cv=10,refit=True).fit(np.array(train_descriptors),train_target.values.ravel())\n",
    "    print('GridSearchCV completed.')\n",
    "\n",
    "    print('\\nBest Estimator:')\n",
    "    print('parameters: %s'%clf.best_estimator_)\n",
    "    print('Mean cross-validated %s score of the best estimator: %.3f'%(cv_metric,clf.best_score_))\n",
    "    print('\\nModel Validation on Test data:')\n",
    "    y_pred = clf.predict(test_descriptors)\n",
    "    \n",
    "    metric = {}\n",
    "    metric['mean squared error'] = round(metrics.regression.mean_squared_error(test_target, y_pred),3)\n",
    "    metric['r2'] = round(metrics.regression.r2_score(test_target, y_pred))\n",
    "    metric['mean absolute error'] = round(metrics.regression.mean_absolute_error(test_target, y_pred))\n",
    "    metric['explained r2'] = round(metrics.regression.explained_variance_score(test_target, y_pred))\n",
    "    metric['mean squared log error'] = round(metrics.regression.mean_squared_log_error(test_target, y_pred))\n",
    "    metric['median absolute error'] = round(metrics.regression.median_absolute_error(test_target, y_pred))\n",
    "\n",
    "    print(metric)\n",
    "    return clf, metric, list(train_descriptors.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset of shape:  (20, 760)\n",
      "\n",
      "Data Split started...\n",
      "Train data shape: (15, 760)\n",
      "Test data shape: (5, 760)\n",
      "Data Split completed.\n",
      "\n",
      "Data Scaling started...\n",
      "Data Scaling completed.\n",
      "\n",
      "Selecting Features...\n",
      "New train data shape: (15, 40)\n",
      "New test data shape: (5, 40)\n",
      "Feature selection completed.\n",
      "\n",
      "GridSearchCV Parameter Grid:\n",
      "{'kernel': ('linear', 'poly', 'rbf', 'sigmoid'), 'epsilon': [0.1, 1], 'C': [1.0, 10.0, 100.0, 1000.0], 'gamma': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}\n",
      "\n",
      "Started GridSearchCV on Training data...\n",
      "GridSearchCV completed.\n",
      "\n",
      "Best Estimator:\n",
      "parameters: SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=100.0,\n",
      "  kernel='sigmoid', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Mean cross-validated r2 score of the best estimator: -9.009\n",
      "\n",
      "Model Validation on Test data:\n",
      "{'mean squared error': 18.533, 'r2': -0.0, 'mean absolute error': 3.0, 'explained r2': -0.0, 'mean squared log error': 0.0, 'median absolute error': 3.0}\n"
     ]
    }
   ],
   "source": [
    "a = svr_model(data, cv_metric='r2', feature_selection='tree based')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
